{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Eshashr/My-Projects/blob/main/MachineLearningProject2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yrJSVIcD2PQA"
      },
      "source": [
        "# Project Two\n",
        "\n",
        "This assignment uses a dataset created for it that we will explore with decision trees, random forest, k-means and association rules. The dataset has four numeric feature columns, A - D, and one binary class column, Z. \n",
        "\n",
        "Make a copy of this file and append your Hollins username to the end of the filename (in the upper left). When you are ready to submit share the file with the Google account I use for data science classes: hollinsdatascience@gmail.com."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1AmlIWadXdax"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import altair as alt\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.tree import plot_tree\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "from mlxtend.preprocessing import TransactionEncoder\n",
        "from mlxtend.frequent_patterns import apriori\n",
        "from mlxtend.frequent_patterns import association_rules"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "51u2hljK06dy",
        "outputId": "7b72724f-e068-40e7-d205-317ddcf8699d"
      },
      "source": [
        "raw_df = pd.read_csv('/content/drive/My Drive/HDS/CMPS 335/Assignments/project_two_data.csv')\n",
        "raw_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>A</th>\n",
              "      <th>B</th>\n",
              "      <th>C</th>\n",
              "      <th>D</th>\n",
              "      <th>Z</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.282312</td>\n",
              "      <td>2.051017</td>\n",
              "      <td>2.498082</td>\n",
              "      <td>0.397016</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.931789</td>\n",
              "      <td>1.692757</td>\n",
              "      <td>2.254481</td>\n",
              "      <td>1.997854</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.539587</td>\n",
              "      <td>3.192589</td>\n",
              "      <td>2.741863</td>\n",
              "      <td>2.328939</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2.031125</td>\n",
              "      <td>1.659627</td>\n",
              "      <td>1.972386</td>\n",
              "      <td>1.949399</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.136543</td>\n",
              "      <td>3.802455</td>\n",
              "      <td>2.053983</td>\n",
              "      <td>1.923515</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          A         B         C         D  Z\n",
              "0  1.282312  2.051017  2.498082  0.397016  0\n",
              "1  1.931789  1.692757  2.254481  1.997854  0\n",
              "2  1.539587  3.192589  2.741863  2.328939  0\n",
              "3  2.031125  1.659627  1.972386  1.949399  0\n",
              "4  2.136543  3.802455  2.053983  1.923515  0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TavXCnYq3zC8"
      },
      "source": [
        "# Create training and test sets using a fixed random state for reproducibility\n",
        "training_set, test_set = train_test_split(raw_df, test_size=0.20, random_state=8)\n",
        "\n",
        "# Use all of the features, excluding Outcome at the end\n",
        "training_features = training_set.iloc[:,:-1]\n",
        "# Targets are at the end\n",
        "training_targets = training_set.iloc[:,-1]\n",
        "\n",
        "# Pull out the same features and targets from test set\n",
        "testing_features = test_set.iloc[:,:-1]\n",
        "testing_targets = test_set.iloc[:,-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NM4Eu1l6jBD1"
      },
      "source": [
        "## Part One\n",
        "\n",
        "1) Train a decision tree classifier, with ccp_apha=0.01 (for post-pruning), on the training data and evaluate it using the score method on the testing data. The score method gives us the accuracy quickly, a reminder of the code is below. Since we are not exploring different hyperparameters you do not need to use cross-validation.\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "dt_model.score(testing_features, testing_targets)\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-g-R6R34MFh"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1HNTSL_JprCM"
      },
      "source": [
        "2) Train a random forest classifier, with ccp_apha=0.01, on the on the training data and evaluate it using the score method on the testing data. Again, no need to use cross-validation here either.\n",
        "\n",
        "How does the random forest model compare to the single decision tree?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "id44kZOy4OOO"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3cz3aq6qN_4"
      },
      "source": [
        "## Part Two\n",
        "\n",
        "In this part we are going to use k-means to cluster on some of the dimensions and reduce our total features from four to two.\n",
        "\n",
        "1) Create a scatter plot of B vs A, meaning B on the y-axis and A on the x-axis, with the points colored by our class column, Z. If you are using Altair, use color='Z:N' to intepret the type of the Z column as nominal in order to get one color for each class.\n",
        "\n",
        "Looking at the scatterplot what might be a good number of clusters?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ablpWWXstNo8"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tun91WmMqsYi"
      },
      "source": [
        "2) Now we are going to create an elbow plot of the inertias across different values of k for clustering on the A and B columns. Calculate the inertia for values of k 1-7. Then create a line plot (ideally also with points) of the inertia vs k. See code below for running k-means with k set to one, I set the random state for purposes of reproducibility on the assignment.\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "km1 = KMeans(n_clusters=1, random_state=0).fit(raw_df.iloc[:,0:2])\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LMs5kOf758VK"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X2N4lo8Jrogv"
      },
      "source": [
        "3) I picked a value of 3 for my k when clustering on A and B. Why did I choose that value?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Wth0HiPrvC4"
      },
      "source": [
        "4) Now, create a scatter plot of D vs C with the points colored by our class column, Z.\n",
        "\n",
        "Looking at the scatterplot what might be a good number of clusters?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "siFEHSnNtWVx"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmEt9DSrr61R"
      },
      "source": [
        "5) Again, create an elbow plot of the inertias across different values of k for clustering on the C and D columns. Calculate the inertia for values of k 1-7. Then create a line plot (ideally also with points) of the inertia vs k."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TSY_c7q35cjC"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7BP0cIOTsOHh"
      },
      "source": [
        "6) I picked a value of 4 for my k when clustering on C and D. Why did I choose that value?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6tJpPjPfy-Ad"
      },
      "source": [
        "## Part Three\n",
        "\n",
        "In this part we will re-train our decision tree and random forest models on the clustered data. We have to dummy-code the cluster labels because the label values are random, i.e. cluster zero is not less than cluster one, and if we leave them as is the models will assume the labels are numeric values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "VM0MoGIY5MEe",
        "outputId": "52f74923-0526-4b9e-b555-c44f669756d9"
      },
      "source": [
        "# This code creates the clustered dataset\n",
        "\n",
        "# Note that we are clustering on the whole dataset, ideally\n",
        "# you would cluster on just the training data and then apply\n",
        "# those clusters to the testing data.\n",
        "# What we are doing here is fine for the assignment,\n",
        "# but not what you would want to do in a real world context.\n",
        "\n",
        "# Cluster the data\n",
        "km_ab = KMeans(n_clusters=3, random_state=0).fit(raw_df.iloc[:,0:2])\n",
        "km_cd = KMeans(n_clusters=4, random_state=0).fit(raw_df.iloc[:,2:4])\n",
        "\n",
        "# Pull out the labels and ensure they are of type category\n",
        "# For get_dummies to work it needs categorical data\n",
        "ab_labels = pd.Series(km_ab.labels_).astype('category')\n",
        "cd_labels = pd.Series(km_cd.labels_).astype('category')\n",
        "class_labels = raw_df['Z'].astype('category')\n",
        "\n",
        "# Create the dataset with dummy-coded cluster columns and our\n",
        "# class labels (which are not dummy-coded)\n",
        "clustered_df = pd.DataFrame({\"AB\":ab_labels, \"CD\":cd_labels})\n",
        "clustered_df = pd.get_dummies(clustered_df)\n",
        "clustered_df['Z'] = class_labels\n",
        "clustered_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>AB_0</th>\n",
              "      <th>AB_1</th>\n",
              "      <th>AB_2</th>\n",
              "      <th>CD_0</th>\n",
              "      <th>CD_1</th>\n",
              "      <th>CD_2</th>\n",
              "      <th>CD_3</th>\n",
              "      <th>Z</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   AB_0  AB_1  AB_2  CD_0  CD_1  CD_2  CD_3  Z\n",
              "0     0     1     0     0     0     1     0  0\n",
              "1     0     1     0     0     0     1     0  0\n",
              "2     0     1     0     0     0     1     0  0\n",
              "3     0     1     0     0     0     1     0  0\n",
              "4     0     1     0     0     0     1     0  0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PxutwVuWgC-7"
      },
      "source": [
        "# Create training and test sets\n",
        "training_set, test_set = train_test_split(clustered_df, test_size=0.20, random_state=8)\n",
        "\n",
        "# Use all of the features, excluding Outcome at the end\n",
        "training_features = training_set.iloc[:,:-1]\n",
        "# Targets are at the end\n",
        "training_targets = training_set.iloc[:,-1]\n",
        "\n",
        "# Pull out the same features and targets from test set\n",
        "testing_features = test_set.iloc[:,:-1]\n",
        "testing_targets = test_set.iloc[:,-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2UcXltnsZPR"
      },
      "source": [
        "1) Train a decision tree classifier, with ccp_apha=0.01, on the on the new clustered training data and evaluate it using the score method on the new testing data. Again, no need to use cross-validation.\n",
        "\n",
        "How does your decision tree's performance compare to the earlier decision tree that trained on the unclustered data?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bPZAL5Eof8MD"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wS2ggw3Svai9"
      },
      "source": [
        "2) Run the code below after training your decision tree to output the tree structure (change dt_model to whatever variable holds your tree). \n",
        "\n",
        "Find each of the paths through the tree. Remember that the arrow going left is the True path and the arrow going right is the False path. The decision tree boundaries are always <= boundaries, which for our dummy-coded data indicates absence. For example, AB_1 <= 0.5 is true for data that does not fall into cluster 1 of the AB clusters, essentially not AB_1. \n",
        "\n",
        "List the paths in logical notation with ~ indicating not, e.g. ~AB_1 & CD_3 & ~AB_2 -> Z_0 where Z_0 indicates class equals 0."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHuwEXqXgscO"
      },
      "source": [
        "# Run this code after training your decision tree to output it.\n",
        "plt.figure(figsize=(20,12))\n",
        "plot_tree(dt_model, feature_names=clustered_df.columns[:-1], class_names=['0','1'])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nwkGcrZPthVh"
      },
      "source": [
        "3) Train a random forest classifier, with ccp_apha=0.01, on the on the new clustered training data and evaluate it using the score method on the new testing data. Again, no need to use cross-validation.\n",
        "\n",
        "How does your random forest's performance compare to the earlier decision tree that trained on the unclustered data?\n",
        "\n",
        "How does it compare to the decision tree trained on the clustered data?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-u34pZHkmGO"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-t6w4HPtw5B"
      },
      "source": [
        "## Part Four\n",
        "\n",
        "This last part looks at the clustered data set using association rules mining. Since the clustering rendered our data categorical, it is now suitable for association rules."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "IB7gMQF3t3E8",
        "outputId": "1f490f43-e744-48c3-b23b-e6431112b4aa"
      },
      "source": [
        "# Create fully dummy coded data for association rules.\n",
        "# We have to also cluster the class labels here so that both\n",
        "# class labels show up in our itemsets.\n",
        "\n",
        "# This code uses the labels that we created earlier when clustering\n",
        "dummies_df = pd.DataFrame({\"AB\":ab_labels, \"CD\":cd_labels, \"Z\":class_labels})\n",
        "dummies_df = pd.get_dummies(clustered_df)\n",
        "dummies_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>AB_0</th>\n",
              "      <th>AB_1</th>\n",
              "      <th>AB_2</th>\n",
              "      <th>CD_0</th>\n",
              "      <th>CD_1</th>\n",
              "      <th>CD_2</th>\n",
              "      <th>CD_3</th>\n",
              "      <th>Z_0</th>\n",
              "      <th>Z_1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   AB_0  AB_1  AB_2  CD_0  CD_1  CD_2  CD_3  Z_0  Z_1\n",
              "0     0     1     0     0     0     1     0    1    0\n",
              "1     0     1     0     0     0     1     0    1    0\n",
              "2     0     1     0     0     0     1     0    1    0\n",
              "3     0     1     0     0     0     1     0    1    0\n",
              "4     0     1     0     0     0     1     0    1    0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n-ucUKNM0UQT"
      },
      "source": [
        "1) Find the rules that have a minimum support of 0.05 and a minimum confidence of 0.75."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XtnxwqVdvHq6"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ptHBFuu0hC5"
      },
      "source": [
        "2) Pull out the rules whose consequents are Z_1 or Z_0. You can do this in two calls if you like."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60bV3u1Tw6nf"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nmD2HyVv08zE"
      },
      "source": [
        "3) (Extra Credit) Find the paths from your decision tree in the rules that you outputted above. You will have to adjust the logic of your decision tree paths to fit the rules. The decision tree looked for the absence of categories and the rules look for the presence of categories.\n",
        "\n",
        "For example, the path ~AB_1 & CD_3 & ~AB_2 -> Z_0 is the same as AB_0 & CD_3 -> Z_0 because if a data point isn't in AB_1 or AB_2 then it must be in AB_0. Similarly ~AB_1 & AB_0 -> Z_0 is the same as AB_0 -> Z_0 because if you are in AB_0 then we already know you can't be in the other AB clusters.\n",
        "\n",
        "Conversions like this can help you adapt the paths to rules that don't have logical nots. It is possible that you can't convert a path to a rule, but you should be able to convert most of the them.\n",
        "\n",
        "For each of your paths from your decision tree list the corresponding rule from you association rules mining. If you can't find a corresponding rule then list that.\n",
        "\n",
        "Note that extra credit can't raise your grade above 100% for this assignment."
      ]
    }
  ]
}