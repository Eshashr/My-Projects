{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Eshashr/My-Projects/blob/main/DataMiningTechniquesProject1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ljOJIcuCB-t7"
      },
      "source": [
        "# Project 1\n",
        "\n",
        "Project 1 is about using cross-validation to explore hyperparameter options for two different types of models. We are using a random forest model and a k-nearest neighbors model.\n",
        "\n",
        "We are using another dataset with a long history in machine learning, a dataset from the Univerisity of Wisconsin on breast cancer.\n",
        "\n",
        "Be sure to mount your drive so that you can access the data set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SBsrD-EXAupb",
        "outputId": "326ffb81-57e8-4d42-c269-bef8305b1c7b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ekp5Jw8enH5s"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5srQlLDZjy3m",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "outputId": "7baf24be-0d5c-4786-f59c-2ebe6a9a2b30"
      },
      "source": [
        "# Read in the dataset and specify the id column to be row indices\n",
        "bcwd = pd.read_csv('/content/drive/MyDrive/HDS/Datasets/breast_cancer_wisconsin_diagnostic.csv', index_col='id')\n",
        "# Recode the classes with numbers\n",
        "bcwd['diagnosis'].replace('M',1, inplace=True)\n",
        "bcwd['diagnosis'].replace('B',0, inplace=True)\n",
        "bcwd.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>diagnosis</th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>fractal_dimension_mean</th>\n",
              "      <th>radius_se</th>\n",
              "      <th>texture_se</th>\n",
              "      <th>perimeter_se</th>\n",
              "      <th>area_se</th>\n",
              "      <th>smoothness_se</th>\n",
              "      <th>compactness_se</th>\n",
              "      <th>concavity_se</th>\n",
              "      <th>concave points_se</th>\n",
              "      <th>symmetry_se</th>\n",
              "      <th>fractal_dimension_se</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>842302</th>\n",
              "      <td>1</td>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>1.0950</td>\n",
              "      <td>0.9053</td>\n",
              "      <td>8.589</td>\n",
              "      <td>153.40</td>\n",
              "      <td>0.006399</td>\n",
              "      <td>0.04904</td>\n",
              "      <td>0.05373</td>\n",
              "      <td>0.01587</td>\n",
              "      <td>0.03003</td>\n",
              "      <td>0.006193</td>\n",
              "      <td>25.38</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>842517</th>\n",
              "      <td>1</td>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>0.5435</td>\n",
              "      <td>0.7339</td>\n",
              "      <td>3.398</td>\n",
              "      <td>74.08</td>\n",
              "      <td>0.005225</td>\n",
              "      <td>0.01308</td>\n",
              "      <td>0.01860</td>\n",
              "      <td>0.01340</td>\n",
              "      <td>0.01389</td>\n",
              "      <td>0.003532</td>\n",
              "      <td>24.99</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84300903</th>\n",
              "      <td>1</td>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>0.7456</td>\n",
              "      <td>0.7869</td>\n",
              "      <td>4.585</td>\n",
              "      <td>94.03</td>\n",
              "      <td>0.006150</td>\n",
              "      <td>0.04006</td>\n",
              "      <td>0.03832</td>\n",
              "      <td>0.02058</td>\n",
              "      <td>0.02250</td>\n",
              "      <td>0.004571</td>\n",
              "      <td>23.57</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84348301</th>\n",
              "      <td>1</td>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.2414</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>0.4956</td>\n",
              "      <td>1.1560</td>\n",
              "      <td>3.445</td>\n",
              "      <td>27.23</td>\n",
              "      <td>0.009110</td>\n",
              "      <td>0.07458</td>\n",
              "      <td>0.05661</td>\n",
              "      <td>0.01867</td>\n",
              "      <td>0.05963</td>\n",
              "      <td>0.009208</td>\n",
              "      <td>14.91</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84358402</th>\n",
              "      <td>1</td>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.1980</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>0.7572</td>\n",
              "      <td>0.7813</td>\n",
              "      <td>5.438</td>\n",
              "      <td>94.44</td>\n",
              "      <td>0.011490</td>\n",
              "      <td>0.02461</td>\n",
              "      <td>0.05688</td>\n",
              "      <td>0.01885</td>\n",
              "      <td>0.01756</td>\n",
              "      <td>0.005115</td>\n",
              "      <td>22.54</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          diagnosis  radius_mean  ...  symmetry_worst  fractal_dimension_worst\n",
              "id                                ...                                         \n",
              "842302            1        17.99  ...          0.4601                  0.11890\n",
              "842517            1        20.57  ...          0.2750                  0.08902\n",
              "84300903          1        19.69  ...          0.3613                  0.08758\n",
              "84348301          1        11.42  ...          0.6638                  0.17300\n",
              "84358402          1        20.29  ...          0.2364                  0.07678\n",
              "\n",
              "[5 rows x 31 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "olkN3PKIo26I"
      },
      "source": [
        "# Create training and test sets\n",
        "# Using a seed for the random number generator to ensure the split is the same every time\n",
        "# for the purposes of this project\n",
        "training_set, test_set = train_test_split(bcwd, test_size=0.20, random_state=42)\n",
        "\n",
        "# Use all of the features, excluding diagnosis at the beginning\n",
        "training_features = training_set.iloc[:,1:]\n",
        "# Targets are at the end\n",
        "training_targets = training_set.iloc[:,0]\n",
        "\n",
        "# Pull out the same features and targets from test set\n",
        "testing_features = test_set.iloc[:,1:]\n",
        "testing_targets = test_set.iloc[:,0]\n",
        "\n",
        "# Use this list of measurements to score your cross-validation results\n",
        "scoring = ['accuracy','precision', 'recall', 'f1']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YkI5Er2jDy26"
      },
      "source": [
        "# Part One\n",
        "\n",
        "In this part we will train a series of random forest models using cross-validation. We will perform what is called a grid search of two different hyperparameters. A grid search explores different combinations of values across multiple hyperparamters. \n",
        "\n",
        "For our purposes, we will explore max_features and max_depth. Max_features specifies how many features each tree has access too. Max_depth limits the growth of the tree. We will explore two values (small and large) for max_features, 4 and 20, and two values of max_depth, 4 and 10. This means a total of 4 models will be created. \n",
        "\n",
        "The first model with max_features=4 and max_depth=5 has code ready to go. You will need to create the other three models that have different pairings of hyperparameter values. Finally, pick your model with the highest test_accuracy and evaluate it on the test set (Code is given for this, but you must set the hyperparameters based on your results).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jaoBYOLaHQwZ"
      },
      "source": [
        "RFM MODEL 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPTFXPon9DuC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0f8936e-1b75-4069-b9d9-c5a1b3ac6dcb"
      },
      "source": [
        "\n",
        "# Sample code of a random forest cross-validation run\n",
        "\n",
        "# Create the random forest model with max_features=4 and max_depth=4\n",
        "rf_model = RandomForestClassifier(criterion='entropy', max_features=4, max_depth=4)\n",
        "\n",
        "# Cross validation calculating multiple metrics\n",
        "rf_model.fit(training_features, training_targets)\n",
        "scores = cross_validate(rf_model, training_features, training_targets, scoring=scoring, return_train_score=True, cv=5)\n",
        "\n",
        "# Average the runs\n",
        "results = pd.DataFrame(scores)\n",
        "results.mean()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "fit_time           0.197134\n",
              "score_time         0.012426\n",
              "test_accuracy      0.951648\n",
              "train_accuracy     0.992857\n",
              "test_precision     0.957452\n",
              "train_precision    1.000000\n",
              "test_recall        0.911230\n",
              "train_recall       0.980773\n",
              "test_f1            0.933093\n",
              "train_f1           0.990290\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NcTFIExiHX-J"
      },
      "source": [
        "RFM MODEL 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0RX5TMT2_lQa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04be742d-8dad-46db-eb0c-63929beda25e"
      },
      "source": [
        "\n",
        "# Create the random forest model with max_features=4 and max_depth=10\n",
        "# Sample code of a random forest cross-validation run\n",
        "\n",
        "rf_model = RandomForestClassifier(criterion='entropy', max_features=4, max_depth=10)\n",
        "\n",
        "# Cross validation calculating multiple metrics\n",
        "rf_model.fit(training_features, training_targets)\n",
        "scores = cross_validate(rf_model, training_features, training_targets, scoring=scoring, return_train_score=True, cv=5)\n",
        "\n",
        "# Average the runs\n",
        "results = pd.DataFrame(scores)\n",
        "results.mean()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "fit_time           0.201579\n",
              "score_time         0.011459\n",
              "test_accuracy      0.958242\n",
              "train_accuracy     1.000000\n",
              "test_precision     0.957945\n",
              "train_precision    1.000000\n",
              "test_recall        0.928877\n",
              "train_recall       1.000000\n",
              "test_f1            0.942316\n",
              "train_f1           1.000000\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r94HaVwiHbbG"
      },
      "source": [
        "RFM MODEL 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k3nn3HAY_ny-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "988bc3ea-99f8-445a-93d6-30b67086f4c5"
      },
      "source": [
        "\n",
        "# Create the random forest model with max_features=20 and max_depth=4\n",
        "rf_model = RandomForestClassifier(criterion='entropy', max_features=20, max_depth=4)\n",
        "\n",
        "# Cross validation calculating multiple metrics\n",
        "rf_model.fit(training_features, training_targets)\n",
        "scores = cross_validate(rf_model, training_features, training_targets, scoring=scoring, return_train_score=True, cv=5)\n",
        "\n",
        "# Average the runs\n",
        "results = pd.DataFrame(scores)\n",
        "results.mean()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "fit_time           0.394423\n",
              "score_time         0.011787\n",
              "test_accuracy      0.953846\n",
              "train_accuracy     0.994505\n",
              "test_precision     0.951721\n",
              "train_precision    1.000000\n",
              "test_recall        0.922995\n",
              "train_recall       0.985207\n",
              "test_f1            0.936455\n",
              "train_f1           0.992543\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1jbr41WqHopu"
      },
      "source": [
        "RFM MODEL 4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Z00oKRPBIpZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2be67f82-601e-4c2c-903a-a11a1d47516c"
      },
      "source": [
        "\n",
        "# Create the random forest model with max_features=20 and max_depth=10\n",
        "rf_model = RandomForestClassifier(criterion='entropy', max_features=20, max_depth=10)\n",
        "\n",
        "# Cross validation calculating multiple metrics\n",
        "rf_model.fit(training_features, training_targets)\n",
        "scores = cross_validate(rf_model, training_features, training_targets, scoring=scoring, return_train_score=True, cv=5)\n",
        "\n",
        "# Average the runs\n",
        "results = pd.DataFrame(scores)\n",
        "results.mean()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "fit_time           0.399752\n",
              "score_time         0.013280\n",
              "test_accuracy      0.960440\n",
              "train_accuracy     1.000000\n",
              "test_precision     0.963675\n",
              "train_precision    1.000000\n",
              "test_recall        0.929055\n",
              "train_recall       1.000000\n",
              "test_f1            0.945330\n",
              "train_f1           1.000000\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XbzY8pq37VIZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0c5d703-2026-4ee6-fee0-3f0b63ee1a16"
      },
      "source": [
        "# Sample code evaluating an rf model on the test set\n",
        "# Customize it as appropriate\n",
        "rf_model = RandomForestClassifier(criterion='entropy', max_features=20, max_depth=10)\n",
        "rf_model.fit(training_features, training_targets)\n",
        "\n",
        "# The score method is quick way of getting the accuracy on the testing data\n",
        "rf_model.score(testing_features, testing_targets)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9649122807017544"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Zh0CHcDGYfQ"
      },
      "source": [
        "## Questions on Part One\n",
        "\n",
        "1) Which model had the highest accuracy test_accuracy score?\n",
        "\n",
        "Model with max_feature = 20 and Max_depth = 10, RFM Model 4, has the highest test accuracy score of 0.960440.\n",
        "\n",
        "2) Which model had the highest test_f1 score?\n",
        "\n",
        "Model with max_feature = 20 and Max_depth = 10, RFM Model 4, has the highest test_f1 score 0.945330.\n",
        "\n",
        "3) Which model had the highest fit_time? Why do you think this is?\n",
        "\n",
        "Model with max_feature = 20 and Max_depth = 10, RFM Model 4, has the highest fit_time score 0.399752. I think its because the depth and feature is the highest in this model.\n",
        "\n",
        "4) Which model had the lowest fit_time? Why do you think this is?\n",
        "\n",
        "Model with max_feature = 4 and Max_depth = 4, RFM Model 1, has the lowest fit_time score 0.197134. I think its because the depth and feature is the lowest in this model.\n",
        "\n",
        "5) Does the model with the highest fit_time have the best f1 score?\n",
        "\n",
        "Yes, RFM Model 4 has the highest fit_time and best f1 score.\n",
        "\n",
        "6) Did you see any evidence of over-fitting from the training accuracy scores?\n",
        "\n",
        "In RFM Model 2 and 4, the traning_accuracy is exactly 1.000, so this is an evidence of overfitting.\n",
        "\n",
        "7) How did your best model in terms of test_accuracy score do when evaluated on the testing set using the score method? How different were the results from the test_accuracy score during cross-validation? \n",
        "\n",
        "RFM Model 4, when evaluated through the score method test_accuracy was 0.9649122807017544 compared to 0.960440 using the cross-validation. The results were pretty similar."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HtVWuxVw5Ihr"
      },
      "source": [
        "# Part Two\n",
        "In part two we will explore using k-nearest neighbors algorithm. First, we will investigate whether scaling the data improves results. Second, we ill use cross-validation to set the k value of our model. \n",
        "\n",
        "Code is given to create and evaluate a k-nearest neighbors model with K=3 on the original data. Code is then given to scale the data. You need to then recreate the knn model with K=3 and evalute its performance on the scaled data. Then create knn models with K=7 and K=12 and evaluate them. Finally, pick your model with the highest test_accuracy and evaluate it on the test set (Code is given for this, but you must set the correct K value).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ShMzVn2h3LiI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be493743-7ad9-4ae5-ad53-3405fdd50041"
      },
      "source": [
        "# Sample code of a KNN cross-validation run\n",
        "\n",
        "# Create KNN model with n_neighbors=3, train on original data\n",
        "knn_model = KNeighborsClassifier(n_neighbors=3)\n",
        "\n",
        "# Cross validation calculating multiple metrics\n",
        "knn_model.fit(training_features, training_targets)\n",
        "scores = cross_validate(knn_model, training_features, training_targets, scoring=scoring, return_train_score=True, cv=5)\n",
        "\n",
        "# Average the runs\n",
        "results = pd.DataFrame(scores)\n",
        "results.mean()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "fit_time           0.002121\n",
              "score_time         0.007111\n",
              "test_accuracy      0.920879\n",
              "train_accuracy     0.948901\n",
              "test_precision     0.934580\n",
              "train_precision    0.964923\n",
              "test_recall        0.846702\n",
              "train_recall       0.895000\n",
              "test_f1            0.886192\n",
              "train_f1           0.928605\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KgkG-JAs79r1"
      },
      "source": [
        "# Scale the features to have a mean of 0 and a standard deviation of 1\n",
        "feature_scaler = StandardScaler().fit(training_features)\n",
        "training_features_scaled = feature_scaler.transform(training_features)\n",
        "testing_features_scaled = feature_scaler.transform(testing_features)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_d0VAc4rIPhj"
      },
      "source": [
        "KNN Model 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2qt8vLe58FKf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac896d69-d9ba-45c2-e4c9-0ebed2232857"
      },
      "source": [
        "\n",
        "# Create KNN model with n_neighbors=3, train on scaled data\n",
        "knn_model = KNeighborsClassifier(n_neighbors=3)\n",
        "\n",
        "# Cross validation calculating multiple metrics\n",
        "knn_model.fit(training_features_scaled, training_targets)\n",
        "scores = cross_validate(knn_model, training_features_scaled, training_targets, scoring=scoring, return_train_score=True, cv=5)\n",
        "\n",
        "# Average the runs\n",
        "results = pd.DataFrame(scores)\n",
        "results.mean()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "fit_time           0.001330\n",
              "score_time         0.008117\n",
              "test_accuracy      0.960440\n",
              "train_accuracy     0.982418\n",
              "test_precision     0.974531\n",
              "train_precision    0.996947\n",
              "test_recall        0.917291\n",
              "train_recall       0.955621\n",
              "test_f1            0.944211\n",
              "train_f1           0.975814\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QHZKNQeaIVPO"
      },
      "source": [
        "KNN Model 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xm3IKheD_l8z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74a4901c-ed99-4c66-c918-e80409a21eb7"
      },
      "source": [
        "\n",
        "# Create KNN model with n_neighbors=7, train on scaled data\n",
        "knn_model = KNeighborsClassifier(n_neighbors=7)\n",
        "\n",
        "# Cross validation calculating multiple metrics\n",
        "knn_model.fit(training_features_scaled, training_targets)\n",
        "scores = cross_validate(knn_model, training_features_scaled, training_targets, scoring=scoring, return_train_score=True, cv=5)\n",
        "\n",
        "# Average the runs\n",
        "results = pd.DataFrame(scores)\n",
        "results.mean()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "fit_time           0.001292\n",
              "score_time         0.008113\n",
              "test_accuracy      0.960440\n",
              "train_accuracy     0.971429\n",
              "test_precision     0.981339\n",
              "train_precision    0.998374\n",
              "test_recall        0.911586\n",
              "train_recall       0.924575\n",
              "test_f1            0.943823\n",
              "train_f1           0.959980\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l95L_ssLIYY7"
      },
      "source": [
        "KNN Model 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F9HJxpoc_nt9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9bf6bc3-1bcd-4c73-aef9-9e3d575ac8f3"
      },
      "source": [
        "\n",
        "# Create KNN model with n_neighbors=12, train on scaled data\n",
        "knn_model = KNeighborsClassifier(n_neighbors=12)\n",
        "\n",
        "# Cross validation calculating multiple metrics\n",
        "knn_model.fit(training_features_scaled, training_targets)\n",
        "scores = cross_validate(knn_model, training_features_scaled, training_targets, scoring=scoring, return_train_score=True, cv=5)\n",
        "\n",
        "# Average the runs\n",
        "results = pd.DataFrame(scores)\n",
        "results.mean()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "fit_time           0.001357\n",
              "score_time         0.008502\n",
              "test_accuracy      0.953846\n",
              "train_accuracy     0.963187\n",
              "test_precision     0.993548\n",
              "train_precision    0.998319\n",
              "test_recall        0.881818\n",
              "train_recall       0.902364\n",
              "test_f1            0.933414\n",
              "train_f1           0.947875\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blcj4iD2_rPk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce3cf1ef-c869-4733-896c-4a228d4a959d"
      },
      "source": [
        "# Sample code evaluating a knn model on the scaled test set\n",
        "# Customize it as appropriate\n",
        "knn_model = KNeighborsClassifier(n_neighbors=3)\n",
        "knn_model.fit(training_features_scaled, training_targets)\n",
        "\n",
        "# The score method is quick way of getting the accuracy on the testing data\n",
        "knn_model.score(testing_features_scaled, testing_targets)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9473684210526315"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S17MEXtH_4vv"
      },
      "source": [
        "## Questions for Part Two\n",
        "\n",
        "1) Did the results from KNN model change when you switched to scaled features?\n",
        "\n",
        "Yes, the results changed but not super significantly.\n",
        "\n",
        "2) Which KNN model had the highest test_accuracy? Did it also have the highest test_f1 score? Is precision or recall higher and what does that say about the model's performance?\n",
        "\n",
        "KNN Model 1, n_neighbors=3, had the highest test_accuracy of 0.960440. Yes this also has the highest test_f1 score of 0.944211. test_precision is 0.974531\n",
        "and test_recall is 0.917291, so the precision is higher than the recall.\n",
        "This means that our model had low number of false positives and returns more relevant results than irrelevant ones (precision), and our model does minimize false negetive buy not as much as precision. In general our system is more accurate if these are both high and it is. \n",
        "\n",
        " It means that our model can measure correctly identifying True Positives than other models (recall high), and ratio between the True Positives and all the Positives is lower than in the other models (precision lower).\n",
        "\n",
        "3) How did your best model in terms of test_accuracy do when evaluated on the testing set? Did the accuracy go up or down and by how much?\n",
        "\n",
        "In the training set, the test_accuracy was 0.9473684210526315, lower than 0.960440 by about 0.02.\n",
        "\n",
        "4) How does your best KNN model compare to your best Random Forest model in terms of accuracy on the testing set? \n",
        "On the testing set, my best Random Forest model's accuracy was 0.9649122807017544 and my best KNN's accuracy was 0.9473684210526315. So, KNN's accuracy was lower.\n",
        "\n",
        "5) How do fit_times compare between the KNN models and the Random Forest models?\n",
        "Random Forest Models fit_times Range: 0.19 - 0.39 (appoximate)\n",
        "KNN models fit_times Range: 0.012 - 0.013 (appoximate)\n",
        "KNN models' fit_times were much lower than that of Random Forest Models.\n"
      ]
    }
  ]
}